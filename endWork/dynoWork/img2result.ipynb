{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Словарь с неисправностей\n",
    "fault_type_list = {\n",
    "    1:\"Нормальная работа\",\n",
    "    2:\"Влияние газа\",\n",
    "    3:\"Утечки в нагнетательной части\",\n",
    "    4:\"Утечки в приемной части\",\n",
    "    5:\"Обрыв/отворот\",\n",
    "    6:\"АСПО\",\n",
    "    7:\"Высокая посадка плунжера\",\n",
    "    8:\"Низкая посадка плунжера\",\n",
    "    9:\"Выход плунжера из цилиндра\",\n",
    "    10:\"Прихват плунжера\",\n",
    "    11:\"Заедание плунжера\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка данных\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),  # Изменение размера до 256x256 пикселей\n",
    "        transforms.ToTensor(),  # Преобразование в тензор (многомерный массив)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),  # Изменение размера до 256x256 пикселей\n",
    "        transforms.ToTensor(),  # Преобразование в тензор\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'img/dyn'  # Каталог с изображениями\n",
    "batch_size = 32  # Размер пакета данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset ImageFolder\n",
       "     Number of datapoints: 325\n",
       "     Root location: img/dyn/train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
       "                ToTensor()\n",
       "            ),\n",
       " 'test': Dataset ImageFolder\n",
       "     Number of datapoints: 73\n",
       "     Root location: img/dyn/test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
       "                ToTensor()\n",
       "            )}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание ImageFolder датасета для обучения и валидации с использованием заданных трансформаций\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'test']}\n",
    "image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DataLoader для загрузки данных с пакетами, перемешиванием и указанием числа рабочих процессов\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=0) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 325, 'test': 73}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определение размеров датасетов для обучения и валидации\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '10', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получение списка классов\n",
    "class_names = image_datasets['train'].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка предварительно обученной модели ResNet18\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получение количества признаков в последнем полносвязном слое\n",
    "num_ftrs = model.fc.in_features\n",
    "num_ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=10, bias=True)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Замена последнего полносвязного слоя на слой с 10 выходами\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # Определение устройства (GPU или CPU)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)  # Перемещение модели на выбранное устройство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение функции потерь (cross-entropy) и оптимизатора (SGD)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0728218203324538\n",
      "Epoch 2, Loss: 0.04980806864224947\n",
      "Epoch 3, Loss: 0.038479567491091216\n",
      "Epoch 4, Loss: 0.027907684766329252\n",
      "Epoch 5, Loss: 0.02291605839362511\n",
      "Epoch 6, Loss: 0.018677076743199274\n",
      "Epoch 7, Loss: 0.014109523433905381\n",
      "Epoch 8, Loss: 0.010975884611789997\n",
      "Epoch 9, Loss: 0.007991544971099267\n",
      "Epoch 10, Loss: 0.007258408849055951\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad() # стохастический градиентный спуск для обновления весов модели\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) # принимает предсказанные значения модели и истинные (ожидаемые) значения (метки) и вычисляет, насколько они различаются.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / dataset_sizes['train']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "torch.save(model.state_dict(), 'dyn_classification_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Классификация нового изображения\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "def classify_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    image = preprocess(image).unsqueeze(0)  # Добавление размерности батча (batch dimension)\n",
    "    image = image.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    return predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1=: 6\n",
      "2=: 4\n",
      "3=: 3\n",
      "4=: 0\n",
      "5=: 5\n",
      "6=: 6\n",
      "7=: 7\n",
      "8=: 9\n",
      "9=: 9\n"
     ]
    }
   ],
   "source": [
    "#Демонстрационная выборка\n",
    "for i in range(1, 10):\n",
    "    new_image_path = f'img/demo/{i}.jpg'\n",
    "    predicted_class = classify_image(new_image_path)\n",
    "    print(f'{i}=: {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нормальная работа:+0-10=0.0\n",
      "Влияние газа:+7-0=1.0\n",
      "Утечки в нагнетательной части:+4-1=0.8\n",
      "Утечки в приемной части:+4-1=0.8\n",
      "Обрыв/отворот:+11-1=0.9166666666666666\n",
      "АСПО:+10-0=1.0\n",
      "Высокая посадка плунжера:+6-1=0.8571428571428571\n",
      "Низкая посадка плунжера:+8-0=1.0\n",
      "Выход плунжера из цилиндра:+8-1=0.8888888888888888\n",
      "Прихват плунжера:+0-1=0.0\n",
      "total:+58-16=0.7837837837837838\n"
     ]
    }
   ],
   "source": [
    "tes_dir = 'img/dyn/test'\n",
    "tpoz = 0\n",
    "tneg = 0\n",
    "for i in range(1, 11):\n",
    "    files_path = f'img/dyn/test/{i}'\n",
    "    files = os.listdir(files_path)\n",
    "    poz = 0\n",
    "    neg = 0\n",
    "    for file_name in files:\n",
    "        full_file_name = f'{files_path}/{file_name}'\n",
    "        predicted_class = classify_image(full_file_name)\n",
    "        if predicted_class == i:\n",
    "            poz += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    tpoz += poz\n",
    "    tneg += neg\n",
    "    print(f'{fault_type_list[i]}:+{poz}-{neg}={poz / (poz + neg) }')\n",
    "print(f'total:+{tpoz}-{tneg}={tpoz / (tpoz + tneg) }')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
